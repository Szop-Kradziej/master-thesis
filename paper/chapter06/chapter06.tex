\chapter{Weryfikacja}
\label{chapter:verify}

Weryfikacja działania platformy odbyła się na podstawie uruchomienia na niej historycznych programów studentów.
Wykorzystane aplikacje zostały utworzone w ramach przedmiotu ”Podstawy Programowania” w semestrze zima 2018.

Proces weryfikacji można podzielić na następujące kroki:
\begin{enumerate}
    \item Przeanalizowanie zadania projektowego i dostępnych aplikacji studenckich.
    \item Lokalne uruchomienie programów.
    \item Zdefiniowanie nowego projektu na platformie wraz z przypadkami testowymi.
    \item Uruchomienie aplikacji studentów z poprzednich lat na platformie i przedstawienie otrzymanych wyników.
    \item Podsumowanie.
\end{enumerate}

Przebieg powyższych kroków został opisany w kolejnych podrozdziałach.


\section{Analiza zadania projektowego}
\label{analysis_students_projects}

W celu weryfikacji platformy posłużono się kodem studentów napisanym w ramach przedmiotu podstawy programowania.
Zadaniem studentów było napisanie programu odzwierciedlającego logikę gry planszowej ”Hey, that’s mine fish”.
Aplikacja miała umożliwiać interaktywny oraz autonomiczny rodzaj rozgrywki.
Zadaniem programów było wczytanie wejściowego układ planszy z pliku, wykonanie zadanej akcji oraz zapisanie zmodyfikowanego układu planszy do pliku.
Format pliku jest jednoznacznie określony w~treści zadania i składa się z:
\begin{itemize}
    \item \textit{Wiersz 1}: \textit{m n} - dwóch wartości liczbowych oznaczających rozmiar planszy.
    \item \textit{Wiersze od 2 do m+1}: \textit{n} pól odseparowanych znakiem spacji, każde z pól jest definiowane przez dwie cyfry.
    Pierwszą oznaczającą liczbę ryb na danym polu (od 0 do 3) oraz druga będącą identyfikatorem gracza znajdującego się obecnie na tym polu (od 1 do 9 lub 0 jeśli pole nie jest zajęte).
    \item \textit{Wiersze od m+2}: trzech pól, reprezentujących kolejno: nazwę gracza (String), identyfikator gracza (od 1 do 9), liczbę punktów uzyskanych przez gracza.
\end{itemize}

Zgodnie z założeniami programy mają przyjmować następujące parametry:
\begin{itemize}
    \item \textit{phase=phase\_mark}, parametr \textit{phase\_mark} może przyjąć jedną z dwóch wartości: \textit{placement} (rozmieszczanie) lub \textit{movement} (ruch).
    \item \textit{penguins=N}, gdzie \textit{N} oznacza liczbę pingwinów (pionków) danego gracza.
    Parametr jest używany tylko w fazie rozmieszczania.
    \item \textit{inputboardfile}, nazwa pliku wejściowego z układem planszy.
    \item \textit{outputboardfile}, nazwa pliku wyjściowego z układem planszy.
    \item \textit{id}, w przypadku podania argumentu \textit{id} program powinien wypisać identyfikator gracza i zakończyć działanie.
\end{itemize}
Pełna definicja zadania projektowego znajduje się w załączniku.

Aplikację rozwiązującą opisane wyżej zadanie można uruchomić na platformie i sprawdzić jej działanie.
Jednak przy założonych parametrach wykonania trudno jest napisać testy akceptacyjne, które pozwolą na automatyczną weryfikację programów.
Do otrzymania korzyści z użytkowania platformy należałoby zmienić założenia co do komend i~przyjmowanych parametrów, tak aby można było napisać odpowiednie i~proste przypadki testowe.
Przykładowo dla fazy ruchu wystarczyłoby dodać dwa parametry wykonania: położenie pingwina, którym chcemy poruszyć oraz docelowe miejsce, w które chcemy go przesunąć.
Faza rozmieszczania również wymagałaby modyfikacji.

W celu zweryfikowania platformy udostępniono siedem projektów napisanych przez studentów i zamieszczonych na platformie GitLab.
Wstępna analiza kodu znajdującego się w repozytoriach pozwoliła ustalić, że spośród dostępnych grup tylko cztery ukończyły zadanie projektowe.
Dwie z pozostałych grup przerwały projekt już na samym początku semestru.
Jeden z zespołów dołączył do innej grupy w trakcie trwania projektu, przez co kod z jego pracy przed przegrupowaniem nie jest analizowany.
Z powyżej przedstawionych powodów do weryfikacji platformy zostały użyte cztery historyczne programy studenckie.

\section{Lokalne uruchomienie historycznych programów studentów}

Lokalne uruchomienie programów studentów można sprowadzić do następujących kroków:
\begin{itemize}
    \item Analiza kodu historycznych programów.
    \item Kompilacja.
    \item Uruchomienie i ocena.
\end{itemize}

Podczas każdego z powyższych kroków napotkano na kilka problemów.
Natrafione trudności zostały omówione w kolejnych podrozdziałach.
Ostatnia sekcja zawiera podsumowanie i wnioski z lokalnego uruchomienia historycznych programów studentów.

\subsection{Analiza kodu}

Projekt był prowadzony przez cały semestr a kod studentów sytematycznie wrzucany na GitLab.
Studenci nie używali tagowania commitów (ciężko też od nich tego wymagać na pierwszym roku studiów).
Z tych powodów granice wykonania kolejnych etapów są zatarte i ciężko je odtworzyć.
Zakłada się więc, że kod znajdujący się na GitLab to ostateczne wersje projektów, które powinny spełniać założenia projektowe i pozwolić na uruchomienie wersji interaktywnej oraz AI.

%team 05
Trzy grupy projektowe zamieszczały swój kod bezpośrednio w repozytorium.
Jeden zespół zamieścił go w tzn. ”snippetach” co utrudniło odszukanie i pobranie go w celu lokalnego uruchomienia.

Kolejnym problemem jest określenie wewnątrz repozytorium, która wersja kodu jest ostateczna i powinna zostać zweryfikowana.
W tym przypadku można posłużyć się datą ostatniego tzw. ”commita”, jednak nie zawsze wydaje się to być odpowiednim rozwiązaniem.
Często zdarza się, że studenci tuż przez końcem projektu (zwłaszcza na samym początku studiów) poprawiają szybko swoje programy.
Takie działania bardzo często doprowadzają do powstawania dodatkowych błędów i powrotu do poprzedniej wersji rozwiązania.
%team 05
W repozytoriach istnieje wiele folderów nazwierających nazwy \textit{final} przykładowo: \textit{Penguins\_final\_code}, \textit{Penguins\_final\_edition\_2}, \textit{Penguins\_final\_edition\_3}.
%team 05 i team 02
Innym problemem jest fakt, że programy dla połowy zespołów były zamieszane w repozytorium w postaci archiwum.
Stąd śledzenie zmian w kodzie przy pomocy systemu kontroli wersji jest bardzo utrudnione.

\subsection{Kompilacja}

Kompilacja programów sprawdza się do indywidualnego przejrzenia kodu każdego z projektów.
%team 04
Spośród wszystkich czterech projektów tylko jeden miał zdefiniowany, zawarty w repozytorium i poprawny plik Makefile.
Trzy pozostałe projekty wymagały własnoręcznej kompilacji.
Spośród nich dwie kompilacje były stosunkowo proste i zakończyły się sukcesem.
Jeden z programów posiadał pojedynczy plik z właściwym kodem aplikacja (rozszerzenie .c) a kompilacja drugiego programu sprowadziła się do skompilowania wszystkich plików w folderze.

%team 02
Dla jednego z zespołów własnoręczna kompilacja finalnej wersji aplikacji nie powiodła się.
Udało się za to uruchomić plik wykonywalny znajdujący się w jednym z podkatalogów.
Aplikacja działała jednak niewłaściwie (próba ustawienia pingwina wypisywała komunikat o poprawnym umieszczniu na ekran jednak plansza była aktualizowana) co doprowadziło do wniosku, że nie jest ona ostateczną wersją programu.
Dla tego zespołu pozyskano finalny kod programu razem z Makefile bezpośrednio od prowadzącego projekt.
Kompilacja tej wersji przebiegła pomyślnie.
Warto jednak zaznaczyć, że uzyskana wersja kodu nie była dostępna przez repozytorium GitLab.

\subsection{Uruchomienie}

Lokalne uruchomienie i ocena sposobu działania programów wymagała również indywidualnego podejścia do każdego z zespołów.
Można założyć, że w celu weryfikacji programów każdy z nich uruchomimy w trybie interaktywnym.
Następnie dla każdego wykonamy identyczne kroki i porównany otrzymane wyniki.

%team 02 i team 04
Dwa z programów uruchomionych w trybie interaktywnym pozwalały na wprowadzenie ruchu gracza i przeprowadzenia założonych testów.
Warto zaznaczyć, że dla jedengo z testowanych programów bardzo szybko można było zauważyć, że logika do rozmieszczania i ruchu pingwinów została napisana przez dwie różne osoby.
Dla fazy rozmieszczania współrzędne na planszy należało podać jako parę (x, y), natomiast dla fazy ruchu przyjmowane one były w postaci (y, x).

Jeden z programów uruchomiony w trybie interaktywnym nie pozwalał na umieszczenie pingwina na planszy i nie zapisywał wyniku do pliku wynikowego.
Wyświetlana przez program plansza była nieprawidłowa i nie pozwalała na poprawne sparsowanie.
Warto dodać, że dla tego programu przejście pomiędzy trybem AI a interaktywnym wymagało zmiany stałej w jednym z plików zawierających kod programu.

Jeden z programów uruchomił się w wersji autmatycznej rozgrywki.
Sprawia to, że przetestowanie dla założonego wcześniej schematu jest niemożliwe, ponieważ nie mamy wpływu na ruch pionków.
Dodatkowo ciężko przez to ocenić, jak zachowuje się program dla przypadków brzegowych, ponieważ nie ma możliwości ustawienia pingwinów w dowolnej lokalizacji.
W tym przypadku ocena sposobu działania programu opierałaby się na przeanalizowaniu algorytmu AI zaimplementowanego przez studentów i porównaniu jego działania z wynikiem symulacji.
Ze względu na brak dokumentacji dotyczącej działania algorymtu AI pominięto ocenę sposobu działania tego programu.

\subsection{Podsumowanie}

Lokalne uruchomienie historycznych programów pokazuje, że proces weryfikacji pracy studentów jest trudnym i czasochłonnym zadniem.
Podejście do każdego z zespołów jest indywidualne na każdym z kroków: analizie kodu, kompilacji, uruchomieniu i ocenie działania.
Rezultat działania każdej z aplikacji jest inny.

Pomimo tych samych parametrów wejściowych wewnętrzna logiki i interfejs użytkownika jest zupełnie różna.
Widać to między innymi na przykładzie ustalania pozycji pingwina na planszy.
Podczas badania programów spotkano różne osoby ustalania położenia identyfikowane przez podanie: dwóch liter, litery i cyfry oraz dwóch cyfr.
Przy czym same współrzędne pól (x,y) lub (y,x) są podawane w niejednoznaczny sposób nawet wewnątrz jednej aplikacji.

Wszystkie powyższe programy zmożna uruchomić na platformie.
Niestety ze względu na to, że zarówno faza rozmieszczania jak i ruchu odbywa się w pełni w trybie interaktywnym i przyjmuje dodatkowe parametry położenia nie da się napisać wartościowych testów akceptacyjnych dla programów historycznych na platformie.
Ocena uruchomienia programów na platformie sprowadza się do sprawdzenia uzyskanych logów.

\section{Definicja projektu wraz z przypadkami testowymi}

Przy założeniu, że wszystkie historyczne programy studenckie spełniają wymagania projektowe definicja projektu na platformie sprowadziłaby się do utworzenia pojedynczego projeku oraz czterach grup projektowych.


TODO: Uzupełnić

W celu uruchomienia programów na platformie został zdefiniowany nowy projekt o nazwie penguins z jednym etapem interactive i trzema przypadkami testowymi.
Tak jak zostało wspomniane wcześniej, dla obecnych założeń projektu ciężko utworzyć black-box testy pozwalające na autmatyczną weryfikację programów.
Sprawdzenie poprawności programów studentów na platformie sprowadziło się więc do skompilowania programów lokalnie, wrzucenia ich na platformę i indywidualnego przejrzenia logów z wynikami ich wykonania.
W przypadku, gdy programy nie zalogowały błędów wykonania uznaje się, że uruchamiają się poprawnie.
Wyniki przeprowadzonych testów zostały przedstawione w tabeli TODO.


\section{Przebieg uruchomienia programów na platformie}

TODO: opisać

Spośród czterech testowanych programów TODO.


TODO: opisać


\section{Podsumowanie}
\label{verification_summary}


TODO: opisać

Jak łatwo zauważyć, taki sposób przetestowania programów nie przynosi wiele korzyści.
Równocześnie pokazuje na jak wiele problemów może napotkać prowadzący podczas weryfkacji pracy studentów, mimo korzystania z narzędzia do wersjonowania kodu.
Takie komplikacje mogą wystąpić podczas sprawdzania każdego z kolejnych etapów i nałożyć się w momencie próby przeprowadzenia integracji programów.
Jednak przy niewielkiej modyfikacji zadania, można osiągnąć dużo lepszą automatyzację procesu oceny efektów pracy zespołów.
W kolejnym rozdziale zostaną omówione zmiany założeń zadania, tak aby osiągnąć korzyści wynikające z korzystania z platformy.
Opisane również zostaną wnioski z przeprowadzenia zmodyfikowanego projektu na grupie testowej.
