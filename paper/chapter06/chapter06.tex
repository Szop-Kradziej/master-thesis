\chapter{Weryfikacja}
\label{chapter:verify}

Weryfikacja działania platformy odbyła się na podstawie uruchomienia programów studentów napisanych w ramach przedmiotu ”Podstawy Programowania” w semestrze zima 2018.
Proces weryfikacji można podzielić na następujące kroki:
\begin{itemize}
    \item Przeanalizowanie zadania projektowego.
    \item Lokalne uruchomienie programów.
    \item Zdefiniowanie nowego projektu na platformie wraz z przypadkami testowymi.
    \item Uruchomienie aplikacji studentów z poprzednich lat na platformie i przedstawienie otrzymanych wyników.
    \item Podsumowanie.
\end{itemize}

Przebieg powyższych kroków został opisany w kolejnych podrozdziałach od \ref{analysis_students_projects} do \ref{verification_summary}.


\section{Analiza zadania projektowego}
\label{analysis_students_projects}

W celu weryfikacji platformy posłużono się kodem studentów napisanym w ramach przedmiotu podstawy programowania.
Zadaniem studentów było napisanie programu umożliwiającego interaktywną oraz autonomiczną grę Hey, that’s mine fish.
Programy miały za zadanie wczytać wejściowy układ planszy z pliku, wykonać zadaną opercaję oraz zapisać zmodyfikowany układ planszy do pliku.
Format pliku jest jednoznacznie określony w treści zadania i składa się z:
\begin{itemize}
    \item Wiersz 1: m n (rozmiar planszy).
    \item Wiersze od 2 do m+1: n pól odseparowanych znakiem spacji, każde z pól zawiera 2 cyfry: liczbę ryb (0-3) oraz cyfrę reprezentującą gracza (1-9 lub 0 jeśli pole nie jest zajęte).
    \item Wiersze od m+2: 3 pól, kolejno: nazwy gracza (string), cyfra reprezentująca gracza (1-9), liczba punktów danego gracza.
\end{itemize}

Zgodnie z założeniami programy mają przyjmować następujące parametry:
\begin{itemize}
    \item phase=phase\_mark, phase\_mark może przyjąć jedną z dwóch wartości: placement lub movement.
    \item penguins=N, gdzie N oznacza liczbę pingwinów (pionków) danego gracza.
    Parametr jest używany tylko w fazie rozmieszczania.
    \item inputboardfile, nazwa pliku wejściowego z układem planszy.
    \item outputboardfile, nazwa pliku wyjściowego z układem planszy.
    \item id, w przypadku podania argumentu "id" program powinien wypisać identyfikator gracza i zakończyć działanie.
\end{itemize}

Program rozwiązujący opisane wyżej zadanie można uruchomić na platformie i sprawdzić jego działanie.
Jednak przy założonych parametrach wykonania trudno jest napisać black-box testy, które pozwolą na automatyczną weryfikację programów.
Do otrzymania korzyści z użytkowania platformy należałoby zmienić założenia co do komend i przyjmowanych parametrów, tak aby można było napisać przypadki testowe.
W tym przypadku wystarczyłoby dla fazy ruchu dodać dwa parametry wykonania: położenie pingwina, którym chcemy poruszyć oraz docelowe miejsce, w które chcemy go przesunąć.
Dla fazy rozmieszczania, należałoby również podać listę położeń w których chcemy umieścić pingwiny.

W celu zbadania platformy udostępnione zostało siedem projektów, napisanych przez studentów w semestrze 2018Z i dostępnych na GitLab.
Wstępna analiza danych pozwoliła ustalić, że spośród dostępnych grup cztery z nich ukończyły zadanie.
Dwie z pozostałych grup przerwały projekt już na początku, a jedna z grup dołączyła do innej, przez co kod z ich pracy nie jest analizowany.


\section{Lokalne uruchomienie historycznych programów studentów}

Podczas lokalnego uruchamiania programów studentów napotykamy na kilka problemów.
Projekt był prowadzony przez cały semestr a kod studentów sytematycznie wrzucany na GitLab.
Studenci nie używali tagowania commitów (ciężko też od nich tego wymagać na 1 roku studiów).
Z tych powodów granice wykonania kolejnych etapów są zatarte i ciężko je odtworzyć.
Zakłada się więc, że kod znajdujący się na GitLab to ostateczne wersje projektów, które powinny spełniać wymienione wyżej założenia.

Kolejnym problemem jest określenie, wewnątrz repozytorium, która wersja kodu jest ostateczna i powinna zostać zweryfikowana.
W tym przypadku można posłużyć się datą ostatniego commita, jednak nie zawsze wydaje się to być odpowiednim rozwiązaniem.
Często zdarza się, że studenci tuż przez końcem projektu (zwłaszcza na samym początku studiów) poprawiają szybko swoje rozwiązania.
Takie działania bardzo często doprowadzają do powstawania dodatkowych błędów i powrotu do poprzedniej wersji rozwiązania.
Tak więc data ostatniego commita może nie określać jednoznacznie wersji kodu która została przedstawiona oficjalnie prowadzącemu.

Kompilacja programów sprawdza się do indywidualnego przejrzenia kodu każdego z projektów.
Spośród wszystkich czterech projektów tylko jeden miał zdefiniowany i poprawny plik Makefile.
Kolejny posiadał tylko jeden plik z właściwym kodem aplikacji (rozszerzenie .c), więc jego kompilacja była prosta.
Dwa pozostałe projekty wymagały własnoręcznej kompilacji przez zdefiniowanie pliku Makefile.

Lokalne uruchomienie i ocena sposobu działania programów wymagała również indywidualnego podejścia do każdego z zespołów.
Można założyć, że w celu weryfikacji programów każdy z nich uruchomimy w trybie interaktywnym.
Następnie dla każdego wykonamy identyczne kroki i porównany otrzymane wyniki.
Jeden z programów uruchomiony w trybie interaktywnym pozwalał na wprowadzenie ruchu gracza i przeprowadzenia założonych testów.
Inny program, posiadający jeden plik z rozszerzeniem .c uruchomił się w wersji autmatycznej rozgrywki.
Sprawia to, że przetestowanie dla założonego wcześniej schematu jest niemożliwe, ponieważ nie mamy wpływu na ruch pionków.
Dodatkowo ciężko przez to ocenić, jak zachowuje się program dla przypadków brzegowych, ponieważ nie ma możliwości ustawienia pingwinów w dowolnej lokalizacji.
W tym przypadku ocena sposobu działania programu opierała się na przeanalizowaniu algorytmu AI zaimplementowanego przez studentów i porównaniu jego działania z wynikiem symulacji.


\section{Definicja projektu na platformie}

W celu uruchomienia programów na platformie został zdefiniowany nowy projekt o nazwie penguins z jednym etapem interactive i trzema przypadkami testowymi.
Tak jak zostało wspomniane wcześniej, dla obecnych założeń projektu ciężko utworzyć black-box testy pozwalające na autmatyczną weryfikację programów.
Sprawdzenie poprawności programów studentów na platformie sprowadziło się więc do skompilowania programów lokalnie, wrzucenia ich na platformę i indywidualnego przejrzenia logów z wynikami ich wykonania.
W przypadku, gdy programy nie zalogowały błędów wykonania uznaje się, że uruchamiają się poprawnie.
Wyniki przeprowadzonych testów zostały przedstawione w tabeli TODO.


\section{Wnioski z uruchomienia programów na platforie}

TODO: opisać

Spośród czterech testowanych programów TODO.


TODO: opisać


\section{Podsumowanie}
\label{verification_summary}


TODO: opisać

Jak łatwo zauważyć, taki sposób przetestowania programów nie przynosi wiele korzyści.
Równocześnie pokazuje na jak wiele problemów może napotkać prowadzący podczas weryfkacji pracy studentów, mimo korzystania z narzędzia do wersjonowania kodu.
Takie komplikacje mogą wystąpić podczas sprawdzania każdego z kolejnych etapów i nałożyć się w momencie próby przeprowadzenia integracji programów.
Jednak przy niewielkiej modyfikacji zadania, można osiągnąć dużo lepszą automatyzację procesu oceny efektów pracy zespołów.
W kolejnym rozdziale zostaną omówione zmiany założeń zadania, tak aby osiągnąć korzyści wynikające z korzystania z platformy.
Opisane również zostaną wnioski z przeprowadzenia zmodyfikowanego projektu na grupie testowej.
